{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20933/20933 [01:53<00:00, 184.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images means: tensor([0.0018, 0.0016, 0.0014])\n",
      "Images std: tensor([0.0008, 0.0008, 0.0009])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.datasets\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "\n",
    "\n",
    "transformations = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = torchvision.datasets.ImageFolder(\"./characters\", transformations)\n",
    "images_means = torch.empty(size=(len(dataset), 3))\n",
    "images_stds = torch.empty(size=(len(dataset), 3))\n",
    "labels_means = torch.empty(size=(len(dataset), 3))\n",
    "labels_stds = torch.empty(size=(len(dataset), 3))\n",
    "\n",
    "for ind, (image, label) in enumerate(tqdm(dataset)):\n",
    "    images_means[ind] = (torch.mean(image, dim=[1,2]))\n",
    "    images_stds[ind] = (torch.std(image, dim=[1,2]))\n",
    "\n",
    "\n",
    "images_mean = images_means.mean(dim=[0])\n",
    "images_std =  images_stds.mean(dim=[0])\n",
    "\n",
    "\n",
    "print(f\"Images means: {images_mean/255}\")\n",
    "print(f\"Images std: {images_std/255}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images in a training set is:  16768\n",
      "The number of images in a test set is:  4224\n",
      "The number of images in validation set is:  6400\n",
      "The number of batches per epoch is:  131\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.datasets\n",
    "import torch\n",
    "import PIL\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 128\n",
    "number_of_labels = 42\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "classes = ('abraham_grampa_simpson',\n",
    "            'agnes_skinner',\n",
    "            'apu_nahasapeemapetilon',\n",
    "            'barney_gumble',\n",
    "            'bart_simpson',\n",
    "            'carl_carlson',\n",
    "            'charles_montgomery_burns',\n",
    "            'chief_wiggum',\n",
    "            'cletus_spuckler',\n",
    "            'comic_book_guy',\n",
    "            'disco_stu',\n",
    "            'edna_krabappel',\n",
    "            'fat_tony',\n",
    "            'gil',\n",
    "            'groundskeeper_willie',\n",
    "            'homer_simpson',\n",
    "            'kent_brockman',\n",
    "            'krusty_the_clown',\n",
    "            'lenny_leonard',\n",
    "            'lionel_hutz',\n",
    "            'lisa_simpson',\n",
    "            'maggie_simpson',\n",
    "            'marge_simpson',\n",
    "            'martin_prince',\n",
    "            'mayor_quimby',\n",
    "            'milhouse_van_houten',\n",
    "            'miss_hoover',\n",
    "            'moe_szyslak',\n",
    "            'ned_flanders',\n",
    "            'nelson_muntz',\n",
    "            'otto_mann',\n",
    "            'patty_bouvier',\n",
    "            'principal_skinner',\n",
    "            'professor_john_frink',\n",
    "            'rainier_wolfcastle',\n",
    "            'ralph_wiggum',\n",
    "            'selma_bouvier',\n",
    "            'sideshow_bob',\n",
    "            'sideshow_mel',\n",
    "            'snake_jailbird',\n",
    "            'troy_mcclure',\n",
    "            'waylon_smithers')\n",
    "class_encoder = {}\n",
    "for i in range(len(classes)):\n",
    "    class_encoder[classes[i]]=i\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = os.listdir(img_dir)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir,self.img_labels[idx])\n",
    "        image = PIL.Image.open(img_path)\n",
    "        label = self.img_labels[idx]\n",
    "        class_indicator = label.rfind('_')\n",
    "        class_str = label[:class_indicator]\n",
    "        label = class_encoder[class_str]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.0018, 0.0016, 0.0014],std=[0.0008, 0.0008, 0.0009]),\n",
    "    transforms.Resize((32,32))\n",
    "])\n",
    "\n",
    "\n",
    "full_dataset = torchvision.datasets.ImageFolder(\"./characters\",transformations)\n",
    "train_dataset,valid_dataset = torch.utils.data.random_split(full_dataset,[0.7, 0.3])\n",
    "train_dataset, test_set = torch.utils.data.random_split(full_dataset,[0.8, 0.2])\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=16)\n",
    "print(\"The number of images in a training set is: \", len(train_loader)*batch_size)\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "print(\"The number of images in a test set is: \", len(test_loader)*batch_size)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "print(\"The number of images in validation set is: \",len(valid_loader)*batch_size)\n",
    "print(\"The number of batches per epoch is: \", len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.ReLU()\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc1 = nn.Linear(512, 42)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.conv(input)\n",
    "        output = self.pool(output)\n",
    "        output = output.view(-1, 512)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "model = Network().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.1, patience=3, verbose=True, threshold=1e-2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import tqdm\n",
    "\n",
    "def saveModel():\n",
    "    path = \"./simpsons.pth\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def testAccuracy():\n",
    "    \n",
    "    model.eval()\n",
    "    metric = torchmetrics.F1Score(task=\"multiclass\", num_classes=42).to(device)\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            metric(predicted, labels)\n",
    "    f1 = metric.compute()\n",
    "\n",
    "    return f1\n",
    "\n",
    "def testAccuracy_1():\n",
    "\n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    metric = torchmetrics.F1Score(task=\"multiclass\", num_classes=42).to(device)\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "            metric(predicted, labels)\n",
    "    f1 = metric.compute()\n",
    "    print(\"F1 metric: \",f1)\n",
    "loss_metric =[]\n",
    "recall_metric=[]\n",
    "accuracy_metric=[]\n",
    "lr_metric=[]\n",
    "\n",
    "def train():\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    print(\"The model will be running on\", device, \"device\")\n",
    "    comment = f' batch_size = {batch_size} lr = {learning_rate}'\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "    for epoch in tqdm.tnrange(num_epochs,position=0,desc=\"Epochs\"):\n",
    "        losses = []\n",
    "        total_correct=0;\n",
    "        total_f1=0;\n",
    "        for _, (images, labels) in enumerate(tqdm.tqdm_notebook(train_loader,position=1,desc=\"Batch iter\",leave=True), 0):\n",
    "\n",
    "            images = Variable(images.to(device))\n",
    "            labels = Variable(labels.to(device))\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            total_correct+= get_num_correct(outputs, labels)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        mean_loss = sum(losses) / len(losses)\n",
    "        scheduler.step(mean_loss)\n",
    "        print(f\"Loss at epoch {epoch} = {mean_loss}\")\n",
    "        f1 = testAccuracy()\n",
    "        print(f\"For epoch {epoch} F1: {f1}\")\n",
    "        tb.add_scalar(\"Loss\", mean_loss, epoch)\n",
    "        tb.add_scalar(\"Correct\", total_correct, epoch)\n",
    "        tb.add_scalar(\"F1\", f1, epoch)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            saveModel()\n",
    "            best_f1 = f1\n",
    "\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "    tb.add_image(\"images\", grid)\n",
    "    tb.add_graph(model, images)\n",
    "    tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "def testClassess():\n",
    "    metric = torchmetrics.F1Score(task=\"multiclass\", num_classes=42,average=None).to(device)\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            metric(predicted, labels)\n",
    "    acc = metric.compute()\n",
    "    for i in range(number_of_labels):\n",
    "        print(f'F1 of {classes[i]} : {acc[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egors\\PycharmProjects\\simpsons_cnn\\venv\\lib\\site-packages\\torchinfo\\torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "C:\\Users\\egors\\PycharmProjects\\simpsons_cnn\\venv\\lib\\site-packages\\torch\\storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n"
     ]
    },
    {
     "data": {
      "text/plain": "=======================================================================================================================================================================================================================\nLayer (type (var_name))                  Input Shape               Output Shape              Param #                   Param %                   Kernel Shape              Mult-Adds                 Trainable\n=======================================================================================================================================================================================================================\nNetwork (Network)                        [128, 3, 32, 32]          [128, 42]                 --                             --                   --                        --                        True\n├─Sequential (conv)                      [128, 3, 32, 32]          [128, 512, 32, 32]        --                             --                   --                        --                        True\n│    └─Conv2d (0)                        [128, 3, 32, 32]          [128, 32, 32, 32]         896                         0.01%                   [3, 3]                    117,440,512               True\n│    └─BatchNorm2d (1)                   [128, 32, 32, 32]         [128, 32, 32, 32]         64                          0.00%                   --                        8,192                     True\n│    └─ReLU (2)                          [128, 32, 32, 32]         [128, 32, 32, 32]         --                             --                   --                        --                        --\n│    └─Conv2d (3)                        [128, 32, 32, 32]         [128, 64, 32, 32]         18,496                      0.26%                   [3, 3]                    2,424,307,712             True\n│    └─BatchNorm2d (4)                   [128, 64, 32, 32]         [128, 64, 32, 32]         128                         0.00%                   --                        16,384                    True\n│    └─ReLU (5)                          [128, 64, 32, 32]         [128, 64, 32, 32]         --                             --                   --                        --                        --\n│    └─Conv2d (6)                        [128, 64, 32, 32]         [128, 64, 32, 32]         36,928                      0.52%                   [3, 3]                    4,840,226,816             True\n│    └─BatchNorm2d (7)                   [128, 64, 32, 32]         [128, 64, 32, 32]         128                         0.00%                   --                        16,384                    True\n│    └─ReLU (8)                          [128, 64, 32, 32]         [128, 64, 32, 32]         --                             --                   --                        --                        --\n│    └─Conv2d (9)                        [128, 64, 32, 32]         [128, 128, 32, 32]        73,856                      1.04%                   [3, 3]                    9,680,453,632             True\n│    └─BatchNorm2d (10)                  [128, 128, 32, 32]        [128, 128, 32, 32]        256                         0.00%                   --                        32,768                    True\n│    └─ReLU (11)                         [128, 128, 32, 32]        [128, 128, 32, 32]        --                             --                   --                        --                        --\n│    └─Conv2d (12)                       [128, 128, 32, 32]        [128, 128, 32, 32]        147,584                     2.08%                   [3, 3]                    19,344,130,048            True\n│    └─BatchNorm2d (13)                  [128, 128, 32, 32]        [128, 128, 32, 32]        256                         0.00%                   --                        32,768                    True\n│    └─ReLU (14)                         [128, 128, 32, 32]        [128, 128, 32, 32]        --                             --                   --                        --                        --\n│    └─Conv2d (15)                       [128, 128, 32, 32]        [128, 256, 32, 32]        295,168                     4.16%                   [3, 3]                    38,688,260,096            True\n│    └─BatchNorm2d (16)                  [128, 256, 32, 32]        [128, 256, 32, 32]        512                         0.01%                   --                        65,536                    True\n│    └─ReLU (17)                         [128, 256, 32, 32]        [128, 256, 32, 32]        --                             --                   --                        --                        --\n│    └─Conv2d (18)                       [128, 256, 32, 32]        [128, 256, 32, 32]        590,080                     8.32%                   [3, 3]                    77,342,965,760            True\n│    └─BatchNorm2d (19)                  [128, 256, 32, 32]        [128, 256, 32, 32]        512                         0.01%                   --                        65,536                    True\n│    └─ReLU (20)                         [128, 256, 32, 32]        [128, 256, 32, 32]        --                             --                   --                        --                        --\n│    └─Conv2d (21)                       [128, 256, 32, 32]        [128, 512, 32, 32]        1,180,160                  16.65%                   [3, 3]                    154,685,931,520           True\n│    └─BatchNorm2d (22)                  [128, 512, 32, 32]        [128, 512, 32, 32]        1,024                       0.01%                   --                        131,072                   True\n│    └─ReLU (23)                         [128, 512, 32, 32]        [128, 512, 32, 32]        --                             --                   --                        --                        --\n│    └─Conv2d (24)                       [128, 512, 32, 32]        [128, 512, 32, 32]        2,359,808                  33.29%                   [3, 3]                    309,304,754,176           True\n│    └─BatchNorm2d (25)                  [128, 512, 32, 32]        [128, 512, 32, 32]        1,024                       0.01%                   --                        131,072                   True\n│    └─ReLU (26)                         [128, 512, 32, 32]        [128, 512, 32, 32]        --                             --                   --                        --                        --\n│    └─Conv2d (27)                       [128, 512, 32, 32]        [128, 512, 32, 32]        2,359,808                  33.29%                   [3, 3]                    309,304,754,176           True\n│    └─BatchNorm2d (28)                  [128, 512, 32, 32]        [128, 512, 32, 32]        1,024                       0.01%                   --                        131,072                   True\n│    └─ReLU (29)                         [128, 512, 32, 32]        [128, 512, 32, 32]        --                             --                   --                        --                        --\n├─AdaptiveAvgPool2d (pool)               [128, 512, 32, 32]        [128, 512, 1, 1]          --                             --                   --                        --                        --\n├─Linear (fc1)                           [128, 512]                [128, 42]                 21,546                      0.30%                   --                        2,757,888                 True\n=======================================================================================================================================================================================================================\nTotal params: 7,089,258\nTrainable params: 7,089,258\nNon-trainable params: 0\nTotal mult-adds (G): 925.74\n=======================================================================================================================================================================================================================\nInput size (MB): 1.57\nForward/backward pass size (MB): 5167.43\nParams size (MB): 28.36\nEstimated Total Size (MB): 5197.36\n======================================================================================================================================================================================================================="
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "\n",
    "\n",
    "torchinfo.summary(model, depth=2, input_size=(128, 3, 32,32), row_settings=[\"var_names\"], verbose=0, col_names=[\n",
    "\"input_size\", \"output_size\", \"num_params\", \"params_percent\", \"kernel_size\", \"mult_adds\", \"trainable\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be running on cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egors\\AppData\\Local\\Temp\\ipykernel_34944\\4222688759.py:53: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for epoch in tqdm.tnrange(num_epochs,position=0,desc=\"Epochs\"):\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "198638784d1f4605958c1ccc511060d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egors\\AppData\\Local\\Temp\\ipykernel_34944\\4222688759.py:57: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for _, (images, labels) in enumerate(tqdm.tqdm_notebook(train_loader,position=1,desc=\"Batch iter\",leave=True), 0):\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33fe84476d8a4053af9b2ab2a7ca8239"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0 = 3.1367073805277585\n",
      "For epoch 0 F1: 0.2369804084300995\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d69d15d3b824e65a8fc7cf80c69de0d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1 = 2.5683108122294187\n",
      "For epoch 1 F1: 0.3841376006603241\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83d204b1201e4636a8976fa57ae22b73"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 2 = 2.1719435462514864\n",
      "For epoch 2 F1: 0.49378880858421326\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ceace5c37b084e0ca28412641e183ae3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 3 = 1.756435775574837\n",
      "For epoch 3 F1: 0.5888676643371582\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6c7b653f32c40e0b7e81253c45ceb75"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 4 = 1.4715098442922112\n",
      "For epoch 4 F1: 0.675107479095459\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5aaea976506402c99670257f487ed29"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 5 = 1.1829104082274984\n",
      "For epoch 5 F1: 0.6624462604522705\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "087ffafe29824deba6144ce8cc7c9ca3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 6 = 1.0395064972739183\n",
      "For epoch 6 F1: 0.7207357883453369\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "baa7b1455ba1404b94ff806de1457cdb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 7 = 0.904232120695915\n",
      "For epoch 7 F1: 0.7467749714851379\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "698b0ba458514685bc4d12067a035ebd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 8 = 0.846235545536944\n",
      "For epoch 8 F1: 0.7818920016288757\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3a9dedc65d24eac8236fc7f6dfb401e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 9 = 0.7755341427471801\n",
      "For epoch 9 F1: 0.8084089756011963\n",
      "Finished Training\n",
      "F1 of abraham_grampa_simpson : 0.5522124171257019\n",
      "F1 of agnes_skinner : 0.0\n",
      "F1 of apu_nahasapeemapetilon : 0.5018726587295532\n",
      "F1 of barney_gumble : 0.0\n",
      "F1 of bart_simpson : 0.44131454825401306\n",
      "F1 of carl_carlson : 0.0\n",
      "F1 of charles_montgomery_burns : 0.5192878246307373\n",
      "F1 of chief_wiggum : 0.640326976776123\n",
      "F1 of cletus_spuckler : 0.0\n",
      "F1 of comic_book_guy : 0.3103448152542114\n",
      "F1 of disco_stu : 0.0\n",
      "F1 of edna_krabappel : 0.42944785952568054\n",
      "F1 of fat_tony : 0.0\n",
      "F1 of gil : 0.0\n",
      "F1 of groundskeeper_willie : 0.0\n",
      "F1 of homer_simpson : 0.5316455960273743\n",
      "F1 of kent_brockman : 0.3333333432674408\n",
      "F1 of krusty_the_clown : 0.7021276354789734\n",
      "F1 of lenny_leonard : 0.039603959769010544\n",
      "F1 of lionel_hutz : 0.0\n",
      "F1 of lisa_simpson : 0.5169491767883301\n",
      "F1 of maggie_simpson : 0.0\n",
      "F1 of marge_simpson : 0.7198795080184937\n",
      "F1 of martin_prince : 0.0\n",
      "F1 of mayor_quimby : 0.0\n",
      "F1 of milhouse_van_houten : 0.6749225854873657\n",
      "F1 of miss_hoover : 0.0\n",
      "F1 of moe_szyslak : 0.5093945860862732\n",
      "F1 of ned_flanders : 0.6423200964927673\n",
      "F1 of nelson_muntz : 0.03999999910593033\n",
      "F1 of otto_mann : 0.0\n",
      "F1 of patty_bouvier : 0.0\n",
      "F1 of principal_skinner : 0.693989098072052\n",
      "F1 of professor_john_frink : 0.0\n",
      "F1 of rainier_wolfcastle : 0.0\n",
      "F1 of ralph_wiggum : 0.0\n",
      "F1 of selma_bouvier : 0.0\n",
      "F1 of sideshow_bob : 0.6593406796455383\n",
      "F1 of sideshow_mel : 0.0\n",
      "F1 of snake_jailbird : 0.0\n",
      "F1 of troy_mcclure : 0.0\n",
      "F1 of waylon_smithers : 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[47], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(torch\u001B[38;5;241m.\u001B[39mload(path))\n\u001B[0;32m      7\u001B[0m testClassess()\n\u001B[1;32m----> 8\u001B[0m \u001B[43mtestAccuracy_1\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[44], line 30\u001B[0m, in \u001B[0;36mtestAccuracy_1\u001B[1;34m()\u001B[0m\n\u001B[0;32m     28\u001B[0m metric \u001B[38;5;241m=\u001B[39m torchmetrics\u001B[38;5;241m.\u001B[39mF1Score(task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m, num_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m---> 30\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m valid_loader:\n\u001B[0;32m     31\u001B[0m         images, labels \u001B[38;5;241m=\u001B[39m data\n\u001B[0;32m     32\u001B[0m         images, labels \u001B[38;5;241m=\u001B[39m images\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\PycharmProjects\\simpsons_cnn\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:442\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    440\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[0;32m    441\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 442\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\simpsons_cnn\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    386\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    387\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[1;32m--> 388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\simpsons_cnn\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1043\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m   1036\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1037\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[0;32m   1038\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[0;32m   1039\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[0;32m   1040\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[0;32m   1041\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[0;32m   1042\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[1;32m-> 1043\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1044\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[0;32m   1045\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[0;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    120\u001B[0m _cleanup()\n\u001B[1;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\context.py:327\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    324\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m    326\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_win32\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[1;32m--> 327\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     92\u001B[0m     reduction\u001B[38;5;241m.\u001B[39mdump(prep_data, to_child)\n\u001B[1;32m---> 93\u001B[0m     \u001B[43mreduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_child\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     95\u001B[0m     set_spawning_popen(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\reduction.py:60\u001B[0m, in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdump\u001B[39m(obj, file, protocol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     59\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m     \u001B[43mForkingPickler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train()\n",
    "    print('Finished Training')\n",
    "    model = Network().to(device)\n",
    "    path = \"simpsons.pth\"\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    testClassess()\n",
    "    testAccuracy_1()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
