{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images in a training set is:  16768\n",
      "The number of images in a test set is:  4224\n",
      "The number of images in validation set is:  6336\n",
      "The number of batches per epoch is:  262\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.datasets\n",
    "import torch\n",
    "import PIL\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 128\n",
    "number_of_labels = 42\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "classes = ('abraham_grampa_simpson',\n",
    "            'agnes_skinner',\n",
    "            'apu_nahasapeemapetilon',\n",
    "            'barney_gumble',\n",
    "            'bart_simpson',\n",
    "            'carl_carlson',\n",
    "            'charles_montgomery_burns',\n",
    "            'chief_wiggum',\n",
    "            'cletus_spuckler',\n",
    "            'comic_book_guy',\n",
    "            'disco_stu',\n",
    "            'edna_krabappel',\n",
    "            'fat_tony',\n",
    "            'gil',\n",
    "            'groundskeeper_willie',\n",
    "            'homer_simpson',\n",
    "            'kent_brockman',\n",
    "            'krusty_the_clown',\n",
    "            'lenny_leonard',\n",
    "            'lionel_hutz',\n",
    "            'lisa_simpson',\n",
    "            'maggie_simpson',\n",
    "            'marge_simpson',\n",
    "            'martin_prince',\n",
    "            'mayor_quimby',\n",
    "            'milhouse_van_houten',\n",
    "            'miss_hoover',\n",
    "            'moe_szyslak',\n",
    "            'ned_flanders',\n",
    "            'nelson_muntz',\n",
    "            'otto_mann',\n",
    "            'patty_bouvier',\n",
    "            'principal_skinner',\n",
    "            'professor_john_frink',\n",
    "            'rainier_wolfcastle',\n",
    "            'ralph_wiggum',\n",
    "            'selma_bouvier',\n",
    "            'sideshow_bob',\n",
    "            'sideshow_mel',\n",
    "            'snake_jailbird',\n",
    "            'troy_mcclure',\n",
    "            'waylon_smithers')\n",
    "class_encoder = {}\n",
    "for i in range(len(classes)):\n",
    "    class_encoder[classes[i]]=i\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = os.listdir(img_dir)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir,self.img_labels[idx])\n",
    "        image = PIL.Image.open(img_path)\n",
    "        label = self.img_labels[idx]\n",
    "        class_indicator = label.rfind('_')\n",
    "        class_str = label[:class_indicator]\n",
    "        label = class_encoder[class_str]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "# Loading and normalizing the data.\n",
    "# Define transformations for the training and test sets\n",
    "transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],std=[0.2023, 0.1994, 0.2010]),\n",
    "    transforms.Resize((32,32))\n",
    "])\n",
    "\n",
    "\n",
    "full_dataset = torchvision.datasets.ImageFolder(\"/home/e.sofronov/cnn_simpsons/characters\",transformations)\n",
    "train_dataset,valid_dataset = torch.utils.data.random_split(full_dataset,[0.7, 0.3])\n",
    "train_dataset, test_set = torch.utils.data.random_split(full_dataset,[0.8, 0.2])\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "print(\"The number of images in a training set is: \", len(train_loader)*batch_size)\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "print(\"The number of images in a test set is: \", len(test_loader)*batch_size)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "print(\"The number of images in validation set is: \",len(valid_loader)*batch_size)\n",
    "print(\"The number of batches per epoch is: \", len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential( \n",
    "                nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(64)\n",
    "        )                      \n",
    "        self.conv2 = nn.Sequential( \n",
    "                nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(64)\n",
    "        )                      \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv4 = nn.Sequential( \n",
    "                nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(128)\n",
    "        )  \n",
    "        self.conv5 = nn.Sequential( \n",
    "                nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(128)\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(256)\n",
    "        )\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(256)\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.conv8 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(512)\n",
    "        )\n",
    "        self.conv9 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(512)\n",
    "        )\n",
    "        self.pool3 = nn.MaxPool2d(2,2)\n",
    "        self.conv10 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(512)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(512*2*2, 42)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = F.relu(self.conv1(input))      \n",
    "        output = F.relu(self.conv2(output))     \n",
    "        output = self.pool(output)                        \n",
    "        output = F.relu(self.conv4(output))     \n",
    "        output = F.relu(self.conv5(output))  \n",
    "        output = self.pool1(output)\n",
    "        output = F.relu(self.conv6(output))     \n",
    "        output = F.relu(self.conv7(output))\n",
    "        output = self.pool2(output)\n",
    "        output = F.relu(self.conv8(output))     \n",
    "        output = F.relu(self.conv9(output))  \n",
    "        output = self.pool3(output)\n",
    "        output = F.relu(self.conv10(output))\n",
    "        output = output.view(-1, 512*2*2)\n",
    "        output = self.fc1(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Instantiate a neural network model \n",
    "model = Network().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    " \n",
    "# Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.1, patience=3, verbose=True, threshold=1e-2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import tqdm\n",
    "import torchmetrics\n",
    "# Function to save the model\n",
    "def saveModel():\n",
    "    path = \"./simpsons.pth\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "# Function to test the model with the test dataset and print the accuracy for the test images\n",
    "def testAccuracy():\n",
    "    \n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    metric = torchmetrics.Recall(task=\"multiclass\", num_classes=42).to(device)\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = model(images)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "            acc = metric(predicted, labels)\n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    print(f\"Recall: {acc}\")\n",
    "    return(accuracy)\n",
    "\n",
    "def train():\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    print(\"The model will be running on\", device, \"device\")\n",
    "    # Convert model parameters and buffers to CPU or Cuda\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in tqdm.notebook.trange(num_epochs):  # loop over the dataset multiple times\n",
    "        losses = []\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader, 0):\n",
    "\n",
    "            images = Variable(images.to(device))\n",
    "            labels = Variable(labels.to(device))\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # predict classes using images from the training set\n",
    "            outputs = model(images)\n",
    "            # compute the loss based on model output and real labels\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "            # backpropagate the loss\n",
    "            loss.backward()\n",
    "            # adjust parameters based on the calculated gradients\n",
    "            optimizer.step()\n",
    "        mean_loss = sum(losses) / len(losses)\n",
    "        scheduler.step(mean_loss)\n",
    "        print(f\"Loss at epoch {epoch} = {mean_loss}\")\n",
    "        # Compute and print the average accuracy fo this epoch when tested over all test images\n",
    "        accuracy = testAccuracy()\n",
    "        print(f'For epoch {epoch} the test accuracy over the whole test set is {accuracy} %')\n",
    "        \n",
    "        # we want to save the model if the accuracy is the best\n",
    "        if accuracy > best_accuracy:\n",
    "            saveModel()\n",
    "            best_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "# Function to test what classes performed well\n",
    "def testClassess():\n",
    "    class_correct = list(0. for i in range(number_of_labels))\n",
    "    class_total = list(0. for i in range(number_of_labels))\n",
    "    metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=42,average=None).to(device)\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            acc = metric(predicted, labels)\n",
    "    for i in range(number_of_labels):\n",
    "        print(f'Accuracy of {classes[i]} : {acc[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=======================================================================================================================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape               Output Shape              Param #                   Param %                   Kernel Shape              Mult-Adds                 Trainable\n",
       "=======================================================================================================================================================================================================================\n",
       "Network (Network)                        [128, 3, 32, 32]          [128, 42]                 --                             --                   --                        --                        True\n",
       "├─Sequential (conv1)                     [128, 3, 32, 32]          [128, 64, 32, 32]         --                             --                   --                        --                        True\n",
       "│    └─Conv2d (0)                        [128, 3, 32, 32]          [128, 32, 32, 32]         896                         0.01%                   [3, 3]                    117,440,512               True\n",
       "│    └─Conv2d (1)                        [128, 32, 32, 32]         [128, 64, 32, 32]         18,496                      0.12%                   [3, 3]                    2,424,307,712             True\n",
       "│    └─BatchNorm2d (2)                   [128, 64, 32, 32]         [128, 64, 32, 32]         128                         0.00%                   --                        16,384                    True\n",
       "├─Sequential (conv2)                     [128, 64, 32, 32]         [128, 64, 32, 32]         --                             --                   --                        --                        True\n",
       "│    └─Conv2d (0)                        [128, 64, 32, 32]         [128, 64, 32, 32]         36,928                      0.23%                   [3, 3]                    4,840,226,816             True\n",
       "│    └─Conv2d (1)                        [128, 64, 32, 32]         [128, 64, 32, 32]         36,928                      0.23%                   [3, 3]                    4,840,226,816             True\n",
       "│    └─BatchNorm2d (2)                   [128, 64, 32, 32]         [128, 64, 32, 32]         128                         0.00%                   --                        16,384                    True\n",
       "├─MaxPool2d (pool)                       [128, 64, 32, 32]         [128, 64, 16, 16]         --                             --                   2                         --                        --\n",
       "├─Sequential (conv4)                     [128, 64, 16, 16]         [128, 128, 16, 16]        --                             --                   --                        --                        True\n",
       "│    └─Conv2d (0)                        [128, 64, 16, 16]         [128, 128, 16, 16]        73,856                      0.47%                   [3, 3]                    2,420,113,408             True\n",
       "│    └─Conv2d (1)                        [128, 128, 16, 16]        [128, 128, 16, 16]        147,584                     0.94%                   [3, 3]                    4,836,032,512             True\n",
       "│    └─BatchNorm2d (2)                   [128, 128, 16, 16]        [128, 128, 16, 16]        256                         0.00%                   --                        32,768                    True\n",
       "├─Sequential (conv5)                     [128, 128, 16, 16]        [128, 128, 16, 16]        --                             --                   --                        --                        True\n",
       "│    └─Conv2d (0)                        [128, 128, 16, 16]        [128, 128, 16, 16]        147,584                     0.94%                   [3, 3]                    4,836,032,512             True\n",
       "│    └─Conv2d (1)                        [128, 128, 16, 16]        [128, 128, 16, 16]        147,584                     0.94%                   [3, 3]                    4,836,032,512             True\n",
       "│    └─BatchNorm2d (2)                   [128, 128, 16, 16]        [128, 128, 16, 16]        256                         0.00%                   --                        32,768                    True\n",
       "├─MaxPool2d (pool1)                      [128, 128, 16, 16]        [128, 128, 8, 8]          --                             --                   2                         --                        --\n",
       "├─Sequential (conv6)                     [128, 128, 8, 8]          [128, 256, 8, 8]          --                             --                   --                        --                        True\n",
       "│    └─Conv2d (0)                        [128, 128, 8, 8]          [128, 256, 8, 8]          295,168                     1.87%                   [3, 3]                    2,418,016,256             True\n",
       "│    └─Conv2d (1)                        [128, 256, 8, 8]          [128, 256, 8, 8]          590,080                     3.75%                   [3, 3]                    4,833,935,360             True\n",
       "│    └─BatchNorm2d (2)                   [128, 256, 8, 8]          [128, 256, 8, 8]          512                         0.00%                   --                        65,536                    True\n",
       "├─Sequential (conv7)                     [128, 256, 8, 8]          [128, 256, 8, 8]          --                             --                   --                        --                        True\n",
       "│    └─Conv2d (0)                        [128, 256, 8, 8]          [128, 256, 8, 8]          590,080                     3.75%                   [3, 3]                    4,833,935,360             True\n",
       "│    └─Conv2d (1)                        [128, 256, 8, 8]          [128, 256, 8, 8]          590,080                     3.75%                   [3, 3]                    4,833,935,360             True\n",
       "│    └─BatchNorm2d (2)                   [128, 256, 8, 8]          [128, 256, 8, 8]          512                         0.00%                   --                        65,536                    True\n",
       "├─MaxPool2d (pool2)                      [128, 256, 8, 8]          [128, 256, 4, 4]          --                             --                   2                         --                        --\n",
       "├─Sequential (conv8)                     [128, 256, 4, 4]          [128, 512, 4, 4]          --                             --                   --                        --                        True\n",
       "│    └─Conv2d (0)                        [128, 256, 4, 4]          [128, 512, 4, 4]          1,180,160                   7.50%                   [3, 3]                    2,416,967,680             True\n",
       "│    └─Conv2d (1)                        [128, 512, 4, 4]          [128, 512, 4, 4]          2,359,808                  14.99%                   [3, 3]                    4,832,886,784             True\n",
       "│    └─BatchNorm2d (2)                   [128, 512, 4, 4]          [128, 512, 4, 4]          1,024                       0.01%                   --                        131,072                   True\n",
       "├─Sequential (conv9)                     [128, 512, 4, 4]          [128, 512, 4, 4]          --                             --                   --                        --                        True\n",
       "│    └─Conv2d (0)                        [128, 512, 4, 4]          [128, 512, 4, 4]          2,359,808                  14.99%                   [3, 3]                    4,832,886,784             True\n",
       "│    └─Conv2d (1)                        [128, 512, 4, 4]          [128, 512, 4, 4]          2,359,808                  14.99%                   [3, 3]                    4,832,886,784             True\n",
       "│    └─BatchNorm2d (2)                   [128, 512, 4, 4]          [128, 512, 4, 4]          1,024                       0.01%                   --                        131,072                   True\n",
       "├─MaxPool2d (pool3)                      [128, 512, 4, 4]          [128, 512, 2, 2]          --                             --                   2                         --                        --\n",
       "├─Sequential (conv10)                    [128, 512, 2, 2]          [128, 512, 2, 2]          --                             --                   --                        --                        True\n",
       "│    └─Conv2d (0)                        [128, 512, 2, 2]          [128, 512, 2, 2]          2,359,808                  14.99%                   [3, 3]                    1,208,221,696             True\n",
       "│    └─Conv2d (1)                        [128, 512, 2, 2]          [128, 512, 2, 2]          2,359,808                  14.99%                   [3, 3]                    1,208,221,696             True\n",
       "│    └─BatchNorm2d (2)                   [128, 512, 2, 2]          [128, 512, 2, 2]          1,024                       0.01%                   --                        131,072                   True\n",
       "├─Linear (fc1)                           [128, 2048]               [128, 42]                 86,058                      0.55%                   --                        11,015,424                True\n",
       "=======================================================================================================================================================================================================================\n",
       "Total params: 15,745,386\n",
       "Trainable params: 15,745,386\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 65.41\n",
       "=======================================================================================================================================================================================================================\n",
       "Input size (MB): 1.57\n",
       "Forward/backward pass size (MB): 727.75\n",
       "Params size (MB): 62.98\n",
       "Estimated Total Size (MB): 792.31\n",
       "======================================================================================================================================================================================================================="
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "\n",
    "\n",
    "torchinfo.summary(model, depth=2, input_size=(64, 3, 32,32), row_settings=[\"var_names\"], verbose=0, col_names=[\n",
    "\"input_size\", \"output_size\", \"num_params\", \"params_percent\", \"kernel_size\", \"mult_adds\", \"trainable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be running on cuda:3 device\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13f1f842faa42c8a5389c2fee9182e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0 = 1.9955431491364048\n",
      "Recall: 0.4615384638309479\n",
      "For epoch 0 the test accuracy over the whole test set is 52.078356426182516 %\n",
      "Loss at epoch 1 = 1.5288326924538795\n",
      "Recall: 0.6538461446762085\n",
      "For epoch 1 the test accuracy over the whole test set is 66.91352126134734 %\n",
      "Loss at epoch 2 = 0.9093284899269352\n",
      "Recall: 0.6153846383094788\n",
      "For epoch 2 the test accuracy over the whole test set is 69.23076923076923 %\n",
      "Loss at epoch 3 = 0.6548920602516364\n",
      "Recall: 0.7692307829856873\n",
      "For epoch 3 the test accuracy over the whole test set is 78.47587195413283 %\n",
      "Loss at epoch 4 = 0.44137871413285495\n",
      "Recall: 0.7692307829856873\n",
      "For epoch 4 the test accuracy over the whole test set is 79.16865742952699 %\n",
      "Loss at epoch 5 = 0.32068000472228947\n",
      "Recall: 0.7307692170143127\n",
      "For epoch 5 the test accuracy over the whole test set is 81.29479216435737 %\n",
      "Loss at epoch 6 = 0.23714347278969433\n",
      "Recall: 0.7692307829856873\n",
      "For epoch 6 the test accuracy over the whole test set is 80.0764452938366 %\n",
      "Loss at epoch 7 = 0.1763680980519484\n",
      "Recall: 0.807692289352417\n",
      "For epoch 7 the test accuracy over the whole test set is 81.36645962732919 %\n",
      "Loss at epoch 8 = 0.1440912877877762\n",
      "Recall: 0.7692307829856873\n",
      "For epoch 8 the test accuracy over the whole test set is 82.22646918299093 %\n",
      "Loss at epoch 9 = 0.10846501713234732\n",
      "Recall: 0.7307692170143127\n",
      "For epoch 9 the test accuracy over the whole test set is 82.6086956521739 %\n",
      "Loss at epoch 10 = 0.09896884241695907\n",
      "Recall: 0.7692307829856873\n",
      "For epoch 10 the test accuracy over the whole test set is 82.41758241758242 %\n",
      "Loss at epoch 11 = 0.07241831612702146\n",
      "Recall: 0.7692307829856873\n",
      "For epoch 11 the test accuracy over the whole test set is 83.01481127568084 %\n",
      "Loss at epoch 12 = 0.09576528204626311\n",
      "Recall: 0.7307692170143127\n",
      "For epoch 12 the test accuracy over the whole test set is 83.4448160535117 %\n",
      "Loss at epoch 13 = 0.05517903195463258\n",
      "Recall: 0.7692307829856873\n",
      "For epoch 13 the test accuracy over the whole test set is 84.71094123268037 %\n",
      "Loss at epoch 14 = 0.08238218611600374\n",
      "Recall: 0.8461538553237915\n",
      "For epoch 14 the test accuracy over the whole test set is 84.32871476349737 %\n",
      "Loss at epoch 15 = 0.0521863521734241\n",
      "Recall: 0.7692307829856873\n",
      "For epoch 15 the test accuracy over the whole test set is 86.00095556617296 %\n",
      "Loss at epoch 16 = 0.045165060045160285\n",
      "Recall: 0.7692307829856873\n",
      "For epoch 16 the test accuracy over the whole test set is 84.59149546106067 %\n",
      "Loss at epoch 17 = 0.055514495295715935\n",
      "Recall: 0.7307692170143127\n",
      "For epoch 17 the test accuracy over the whole test set is 83.39703774486384 %\n",
      "Loss at epoch 18 = 0.05397468718001619\n",
      "Recall: 0.807692289352417\n",
      "For epoch 18 the test accuracy over the whole test set is 83.73148590539896 %\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"/home/e.sofronov/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/e.sofronov/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 61, in fetch\n    return self.collate_fn(data)\n  File \"/home/e.sofronov/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/e.sofronov/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 143, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/e.sofronov/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 143, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/e.sofronov/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 120, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/home/e.sofronov/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 161, in collate_tensor_fn\n    storage = elem.storage()._new_shared(numel, device=elem.device)\n  File \"/home/e.sofronov/anaconda3/lib/python3.9/site-packages/torch/storage.py\", line 635, in _new_shared\n    untyped_storage = torch.UntypedStorage._new_shared(size * self.element_size(), device=device)\n  File \"/home/e.sofronov/anaconda3/lib/python3.9/site-packages/torch/storage.py\", line 223, in _new_shared\n    return cls._new_using_fd_cpu(size)\nRuntimeError: unable to write to file </torch_60600_1688058977_64>: No space left on device (28)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1673/389503460.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtestClassess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1673/1622284356.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"/home/e.sofronov/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/e.sofronov/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 61, in fetch\n    return self.collate_fn(data)\n  File \"/home/e.sofronov/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/e.sofronov/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 143, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/e.sofronov/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 143, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/e.sofronov/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 120, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/home/e.sofronov/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 161, in collate_tensor_fn\n    storage = elem.storage()._new_shared(numel, device=elem.device)\n  File \"/home/e.sofronov/anaconda3/lib/python3.9/site-packages/torch/storage.py\", line 635, in _new_shared\n    untyped_storage = torch.UntypedStorage._new_shared(size * self.element_size(), device=device)\n  File \"/home/e.sofronov/anaconda3/lib/python3.9/site-packages/torch/storage.py\", line 223, in _new_shared\n    return cls._new_using_fd_cpu(size)\nRuntimeError: unable to write to file </torch_60600_1688058977_64>: No space left on device (28)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    train()\n",
    "    print('Finished Training')\n",
    "    testClassess()\n",
    "    model = Network().to(device)\n",
    "    path = \"simpsons.pth\"\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    #testBatch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
