{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images in a training set is:  16768\n",
      "The number of images in a test set is:  4224\n",
      "The number of images in validation set is:  6400\n",
      "The number of batches per epoch is:  131\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.datasets\n",
    "import torch\n",
    "import PIL\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 128\n",
    "number_of_labels = 42\n",
    "learning_rate = 0.001\n",
    "num_epochs = 150\n",
    "classes = ('abraham_grampa_simpson',\n",
    "            'agnes_skinner',\n",
    "            'apu_nahasapeemapetilon',\n",
    "            'barney_gumble',\n",
    "            'bart_simpson',\n",
    "            'carl_carlson',\n",
    "            'charles_montgomery_burns',\n",
    "            'chief_wiggum',\n",
    "            'cletus_spuckler',\n",
    "            'comic_book_guy',\n",
    "            'disco_stu',\n",
    "            'edna_krabappel',\n",
    "            'fat_tony',\n",
    "            'gil',\n",
    "            'groundskeeper_willie',\n",
    "            'homer_simpson',\n",
    "            'kent_brockman',\n",
    "            'krusty_the_clown',\n",
    "            'lenny_leonard',\n",
    "            'lionel_hutz',\n",
    "            'lisa_simpson',\n",
    "            'maggie_simpson',\n",
    "            'marge_simpson',\n",
    "            'martin_prince',\n",
    "            'mayor_quimby',\n",
    "            'milhouse_van_houten',\n",
    "            'miss_hoover',\n",
    "            'moe_szyslak',\n",
    "            'ned_flanders',\n",
    "            'nelson_muntz',\n",
    "            'otto_mann',\n",
    "            'patty_bouvier',\n",
    "            'principal_skinner',\n",
    "            'professor_john_frink',\n",
    "            'rainier_wolfcastle',\n",
    "            'ralph_wiggum',\n",
    "            'selma_bouvier',\n",
    "            'sideshow_bob',\n",
    "            'sideshow_mel',\n",
    "            'snake_jailbird',\n",
    "            'troy_mcclure',\n",
    "            'waylon_smithers')\n",
    "class_encoder = {}\n",
    "for i in range(len(classes)):\n",
    "    class_encoder[classes[i]]=i\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = os.listdir(img_dir)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir,self.img_labels[idx])\n",
    "        image = PIL.Image.open(img_path)\n",
    "        label = self.img_labels[idx]\n",
    "        class_indicator = label.rfind('_')\n",
    "        class_str = label[:class_indicator]\n",
    "        label = class_encoder[class_str]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "# Loading and normalizing the data.\n",
    "# Define transformations for the training and test sets\n",
    "transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],std=[0.2023, 0.1994, 0.2010]),\n",
    "    transforms.Resize((32,32))\n",
    "])\n",
    "\n",
    "\n",
    "full_dataset = torchvision.datasets.ImageFolder(\"./characters\",transformations)\n",
    "train_dataset,valid_dataset = torch.utils.data.random_split(full_dataset,[0.7, 0.3])\n",
    "train_dataset, test_set = torch.utils.data.random_split(full_dataset,[0.8, 0.2])\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "print(\"The number of images in a training set is: \", len(train_loader)*batch_size)\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "print(\"The number of images in a test set is: \", len(test_loader)*batch_size)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "print(\"The number of images in validation set is: \",len(valid_loader)*batch_size)\n",
    "print(\"The number of batches per epoch is: \", len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv4 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(128)\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(128)\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(256)\n",
    "        )\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(256)\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.conv8 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(512)\n",
    "        )\n",
    "        self.conv9 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(512)\n",
    "        )\n",
    "        self.pool3 = nn.MaxPool2d(2,2)\n",
    "        self.conv10 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(512)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(512*2*2, 42)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = F.relu(self.conv1(input))\n",
    "        output = F.relu(self.conv2(output))\n",
    "        output = self.pool(output)\n",
    "        output = F.relu(self.conv4(output))\n",
    "        output = F.relu(self.conv5(output))\n",
    "        output = self.pool1(output)\n",
    "        output = F.relu(self.conv6(output))\n",
    "        output = F.relu(self.conv7(output))\n",
    "        output = self.pool2(output)\n",
    "        output = F.relu(self.conv8(output))\n",
    "        output = F.relu(self.conv9(output))\n",
    "        output = self.pool3(output)\n",
    "        output = F.relu(self.conv10(output))\n",
    "        output = output.view(-1, 512*2*2)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "# Instantiate a neural network model \n",
    "model = Network().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    " \n",
    "# Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.1, patience=3, verbose=True, threshold=1e-2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import tqdm\n",
    "# Function to save the model\n",
    "def saveModel():\n",
    "    path = \"./simpsons.pth\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "# Function to test the model with the test dataset and print the accuracy for the test images\n",
    "def testAccuracy():\n",
    "    \n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    metric = torchmetrics.Recall(task=\"multiclass\", num_classes=42).to(device)\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = model(images)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "            metric(predicted, labels)\n",
    "    recall = metric.compute()\n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return accuracy, recall\n",
    "\n",
    "loss_metric =[]\n",
    "recall_metric=[]\n",
    "accuracy_metric=[]\n",
    "lr_metric=[]\n",
    "\n",
    "def train():\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    # Define your execution device\n",
    "    print(\"The model will be running on\", device, \"device\")\n",
    "    # Convert model parameters and buffers to CPU or Cuda\n",
    "    for epoch in tqdm.tnrange(num_epochs,position=0,desc=\"Epochs\"):  # loop over the dataset multiple times\n",
    "        losses = []\n",
    "\n",
    "        for i, (images, labels) in enumerate(tqdm.tqdm_notebook(train_loader,position=1,desc=\"Batch iter\",leave=True), 0):\n",
    "\n",
    "            images = Variable(images.to(device))\n",
    "            labels = Variable(labels.to(device))\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # predict classes using images from the training set\n",
    "            outputs = model(images)\n",
    "            # compute the loss based on model output and real labels\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "            # backpropagate the loss\n",
    "            loss.backward()\n",
    "            # adjust parameters based on the calculated gradients\n",
    "            optimizer.step()\n",
    "        mean_loss = sum(losses) / len(losses)\n",
    "        scheduler.step(mean_loss)\n",
    "        print(f\"Loss at epoch {epoch} = {mean_loss}\")\n",
    "        # Compute and print the average accuracy fo this epoch when tested over all test images\n",
    "        accuracy, recall = testAccuracy()\n",
    "        loss_metric.append(mean_loss)\n",
    "        accuracy_metric.append(accuracy)\n",
    "        recall_metric.append(recall)\n",
    "        print(f\"For epoch {epoch} recall: {recall}\")\n",
    "        print(f'For epoch {epoch} the test accuracy over the whole test set is {accuracy} %')\n",
    "        \n",
    "        # we want to save the model if the accuracy is the best\n",
    "        if recall > best_accuracy:\n",
    "            saveModel()\n",
    "            best_accuracy = recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "# Function to test what classes performed well\n",
    "def testClassess():\n",
    "    metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=42,average=None).to(device)\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            metric(predicted, labels)\n",
    "    acc = metric.compute()\n",
    "    for i in range(number_of_labels):\n",
    "        print(f'Accuracy of {classes[i]} : {acc[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egors\\simpsons_cnn\\venv\\lib\\site-packages\\torchinfo\\torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "C:\\Users\\egors\\simpsons_cnn\\venv\\lib\\site-packages\\torch\\storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n"
     ]
    },
    {
     "data": {
      "text/plain": "=======================================================================================================================================================================================================================\nLayer (type (var_name))                  Input Shape               Output Shape              Param #                   Param %                   Kernel Shape              Mult-Adds                 Trainable\n=======================================================================================================================================================================================================================\nNetwork (Network)                        [32, 3, 32, 32]           [32, 42]                  --                             --                   --                        --                        True\n├─Sequential (conv1)                     [32, 3, 32, 32]           [32, 64, 32, 32]          --                             --                   --                        --                        True\n│    └─Conv2d (0)                        [32, 3, 32, 32]           [32, 32, 32, 32]          896                         0.01%                   [3, 3]                    29,360,128                True\n│    └─Conv2d (1)                        [32, 32, 32, 32]          [32, 64, 32, 32]          18,496                      0.12%                   [3, 3]                    606,076,928               True\n│    └─BatchNorm2d (2)                   [32, 64, 32, 32]          [32, 64, 32, 32]          128                         0.00%                   --                        4,096                     True\n├─Sequential (conv2)                     [32, 64, 32, 32]          [32, 64, 32, 32]          --                             --                   --                        --                        True\n│    └─Conv2d (0)                        [32, 64, 32, 32]          [32, 64, 32, 32]          36,928                      0.23%                   [3, 3]                    1,210,056,704             True\n│    └─Conv2d (1)                        [32, 64, 32, 32]          [32, 64, 32, 32]          36,928                      0.23%                   [3, 3]                    1,210,056,704             True\n│    └─BatchNorm2d (2)                   [32, 64, 32, 32]          [32, 64, 32, 32]          128                         0.00%                   --                        4,096                     True\n├─MaxPool2d (pool)                       [32, 64, 32, 32]          [32, 64, 16, 16]          --                             --                   2                         --                        --\n├─Sequential (conv4)                     [32, 64, 16, 16]          [32, 128, 16, 16]         --                             --                   --                        --                        True\n│    └─Conv2d (0)                        [32, 64, 16, 16]          [32, 128, 16, 16]         73,856                      0.47%                   [3, 3]                    605,028,352               True\n│    └─Conv2d (1)                        [32, 128, 16, 16]         [32, 128, 16, 16]         147,584                     0.94%                   [3, 3]                    1,209,008,128             True\n│    └─BatchNorm2d (2)                   [32, 128, 16, 16]         [32, 128, 16, 16]         256                         0.00%                   --                        8,192                     True\n├─Sequential (conv5)                     [32, 128, 16, 16]         [32, 128, 16, 16]         --                             --                   --                        --                        True\n│    └─Conv2d (0)                        [32, 128, 16, 16]         [32, 128, 16, 16]         147,584                     0.94%                   [3, 3]                    1,209,008,128             True\n│    └─Conv2d (1)                        [32, 128, 16, 16]         [32, 128, 16, 16]         147,584                     0.94%                   [3, 3]                    1,209,008,128             True\n│    └─BatchNorm2d (2)                   [32, 128, 16, 16]         [32, 128, 16, 16]         256                         0.00%                   --                        8,192                     True\n├─MaxPool2d (pool1)                      [32, 128, 16, 16]         [32, 128, 8, 8]           --                             --                   2                         --                        --\n├─Sequential (conv6)                     [32, 128, 8, 8]           [32, 256, 8, 8]           --                             --                   --                        --                        True\n│    └─Conv2d (0)                        [32, 128, 8, 8]           [32, 256, 8, 8]           295,168                     1.87%                   [3, 3]                    604,504,064               True\n│    └─Conv2d (1)                        [32, 256, 8, 8]           [32, 256, 8, 8]           590,080                     3.75%                   [3, 3]                    1,208,483,840             True\n│    └─BatchNorm2d (2)                   [32, 256, 8, 8]           [32, 256, 8, 8]           512                         0.00%                   --                        16,384                    True\n├─Sequential (conv7)                     [32, 256, 8, 8]           [32, 256, 8, 8]           --                             --                   --                        --                        True\n│    └─Conv2d (0)                        [32, 256, 8, 8]           [32, 256, 8, 8]           590,080                     3.75%                   [3, 3]                    1,208,483,840             True\n│    └─Conv2d (1)                        [32, 256, 8, 8]           [32, 256, 8, 8]           590,080                     3.75%                   [3, 3]                    1,208,483,840             True\n│    └─BatchNorm2d (2)                   [32, 256, 8, 8]           [32, 256, 8, 8]           512                         0.00%                   --                        16,384                    True\n├─MaxPool2d (pool2)                      [32, 256, 8, 8]           [32, 256, 4, 4]           --                             --                   2                         --                        --\n├─Sequential (conv8)                     [32, 256, 4, 4]           [32, 512, 4, 4]           --                             --                   --                        --                        True\n│    └─Conv2d (0)                        [32, 256, 4, 4]           [32, 512, 4, 4]           1,180,160                   7.50%                   [3, 3]                    604,241,920               True\n│    └─Conv2d (1)                        [32, 512, 4, 4]           [32, 512, 4, 4]           2,359,808                  14.99%                   [3, 3]                    1,208,221,696             True\n│    └─BatchNorm2d (2)                   [32, 512, 4, 4]           [32, 512, 4, 4]           1,024                       0.01%                   --                        32,768                    True\n├─Sequential (conv9)                     [32, 512, 4, 4]           [32, 512, 4, 4]           --                             --                   --                        --                        True\n│    └─Conv2d (0)                        [32, 512, 4, 4]           [32, 512, 4, 4]           2,359,808                  14.99%                   [3, 3]                    1,208,221,696             True\n│    └─Conv2d (1)                        [32, 512, 4, 4]           [32, 512, 4, 4]           2,359,808                  14.99%                   [3, 3]                    1,208,221,696             True\n│    └─BatchNorm2d (2)                   [32, 512, 4, 4]           [32, 512, 4, 4]           1,024                       0.01%                   --                        32,768                    True\n├─MaxPool2d (pool3)                      [32, 512, 4, 4]           [32, 512, 2, 2]           --                             --                   2                         --                        --\n├─Sequential (conv10)                    [32, 512, 2, 2]           [32, 512, 2, 2]           --                             --                   --                        --                        True\n│    └─Conv2d (0)                        [32, 512, 2, 2]           [32, 512, 2, 2]           2,359,808                  14.99%                   [3, 3]                    302,055,424               True\n│    └─Conv2d (1)                        [32, 512, 2, 2]           [32, 512, 2, 2]           2,359,808                  14.99%                   [3, 3]                    302,055,424               True\n│    └─BatchNorm2d (2)                   [32, 512, 2, 2]           [32, 512, 2, 2]           1,024                       0.01%                   --                        32,768                    True\n├─Linear (fc1)                           [32, 2048]                [32, 42]                  86,058                      0.55%                   --                        2,753,856                 True\n=======================================================================================================================================================================================================================\nTotal params: 15,745,386\nTrainable params: 15,745,386\nNon-trainable params: 0\nTotal mult-adds (G): 16.35\n=======================================================================================================================================================================================================================\nInput size (MB): 0.39\nForward/backward pass size (MB): 181.94\nParams size (MB): 62.98\nEstimated Total Size (MB): 245.31\n======================================================================================================================================================================================================================="
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "\n",
    "\n",
    "torchinfo.summary(model, depth=2, input_size=(32, 3, 32,32), row_settings=[\"var_names\"], verbose=0, col_names=[\n",
    "\"input_size\", \"output_size\", \"num_params\", \"params_percent\", \"kernel_size\", \"mult_adds\", \"trainable\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be running on cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egors\\AppData\\Local\\Temp\\ipykernel_26340\\3129395804.py:43: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for epoch in tqdm.tnrange(num_epochs,position=0,desc=\"Epochs\"):  # loop over the dataset multiple times\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epochs:   0%|          | 0/150 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f899098a0d954231a94bc3d3fc74c01c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egors\\AppData\\Local\\Temp\\ipykernel_26340\\3129395804.py:46: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i, (images, labels) in enumerate(tqdm.tqdm_notebook(train_loader,position=1,desc=\"Batch iter\",leave=True), 0):\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7810e3b3ba4a405fa1cd304075e22b69"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0 = 2.173261076439428\n",
      "For epoch 0 recall: 0.5711897015571594\n",
      "For epoch 0 the test accuracy over the whole test set is 57.11896798853321 %\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56291455a128451fa0c1c2cfc542abad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1 = 2.2685199184272125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m----> 2\u001B[0m     \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFinished Training\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m     model \u001B[38;5;241m=\u001B[39m Network()\u001B[38;5;241m.\u001B[39mto(device)\n",
      "Cell \u001B[1;32mIn[5], line 66\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m()\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoss at epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmean_loss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     65\u001B[0m \u001B[38;5;66;03m# Compute and print the average accuracy fo this epoch when tested over all test images\u001B[39;00m\n\u001B[1;32m---> 66\u001B[0m accuracy, recall \u001B[38;5;241m=\u001B[39m \u001B[43mtestAccuracy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     67\u001B[0m loss_metric\u001B[38;5;241m.\u001B[39mappend(mean_loss)\n\u001B[0;32m     68\u001B[0m accuracy_metric\u001B[38;5;241m.\u001B[39mappend(accuracy)\n",
      "Cell \u001B[1;32mIn[5], line 16\u001B[0m, in \u001B[0;36mtestAccuracy\u001B[1;34m()\u001B[0m\n\u001B[0;32m     14\u001B[0m metric \u001B[38;5;241m=\u001B[39m torchmetrics\u001B[38;5;241m.\u001B[39mRecall(task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m, num_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m---> 16\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m test_loader:\n\u001B[0;32m     17\u001B[0m         images, labels \u001B[38;5;241m=\u001B[39m data\n\u001B[0;32m     18\u001B[0m         images, labels \u001B[38;5;241m=\u001B[39m images\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\simpsons_cnn\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    632\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    633\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 634\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    635\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    636\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    637\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    638\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\simpsons_cnn\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[0;32m   1328\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m-> 1329\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1330\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1331\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[0;32m   1332\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[1;32m~\\simpsons_cnn\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1295\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1291\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[0;32m   1292\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[0;32m   1293\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1294\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m-> 1295\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1296\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[0;32m   1297\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\simpsons_cnn\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1120\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_get_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_utils\u001B[38;5;241m.\u001B[39mMP_STATUS_CHECK_INTERVAL):\n\u001B[0;32m   1121\u001B[0m     \u001B[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001B[39;00m\n\u001B[0;32m   1122\u001B[0m     \u001B[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1130\u001B[0m     \u001B[38;5;66;03m# Returns a 2-tuple:\u001B[39;00m\n\u001B[0;32m   1131\u001B[0m     \u001B[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1133\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1134\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n\u001B[0;32m   1135\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1136\u001B[0m         \u001B[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001B[39;00m\n\u001B[0;32m   1137\u001B[0m         \u001B[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001B[39;00m\n\u001B[0;32m   1138\u001B[0m         \u001B[38;5;66;03m# worker failures.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\queues.py:113\u001B[0m, in \u001B[0;36mQueue.get\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[0;32m    112\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m deadline \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[1;32m--> 113\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    114\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll():\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\connection.py:262\u001B[0m, in \u001B[0;36m_ConnectionBase.poll\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    260\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_closed()\n\u001B[0;32m    261\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_readable()\n\u001B[1;32m--> 262\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\connection.py:335\u001B[0m, in \u001B[0;36mPipeConnection._poll\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    332\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_got_empty_message \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m    333\u001B[0m             _winapi\u001B[38;5;241m.\u001B[39mPeekNamedPipe(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle)[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m    334\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 335\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\connection.py:884\u001B[0m, in \u001B[0;36mwait\u001B[1;34m(object_list, timeout)\u001B[0m\n\u001B[0;32m    881\u001B[0m                 ready_objects\u001B[38;5;241m.\u001B[39madd(o)\n\u001B[0;32m    882\u001B[0m                 timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m--> 884\u001B[0m     ready_handles \u001B[38;5;241m=\u001B[39m \u001B[43m_exhaustive_wait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwaithandle_to_obj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeys\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    885\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    886\u001B[0m     \u001B[38;5;66;03m# request that overlapped reads stop\u001B[39;00m\n\u001B[0;32m    887\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m ov \u001B[38;5;129;01min\u001B[39;00m ov_list:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\connection.py:816\u001B[0m, in \u001B[0;36m_exhaustive_wait\u001B[1;34m(handles, timeout)\u001B[0m\n\u001B[0;32m    814\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    815\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m L:\n\u001B[1;32m--> 816\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43m_winapi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mWaitForMultipleObjects\u001B[49m\u001B[43m(\u001B[49m\u001B[43mL\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    817\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;241m==\u001B[39m WAIT_TIMEOUT:\n\u001B[0;32m    818\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train()\n",
    "    print('Finished Training')\n",
    "    model = Network().to(device)\n",
    "    path = \"simpsons.pth\"\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    testClassess()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "epochs = [i for i in range(num_epochs)]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(recall_metric,epochs,label=\"Recall\")\n",
    "ax.plot(loss_metric,epochs,label=\"Loss\")\n",
    "ax.plot(accuracy_metric,epochs,label=\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
