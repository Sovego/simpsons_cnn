{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images in a training set is:  16768\n",
      "The number of images in a test set is:  4224\n",
      "The number of images in validation set is:  6400\n",
      "The number of batches per epoch is:  131\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.datasets\n",
    "import torch\n",
    "import PIL\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 128\n",
    "number_of_labels = 42\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "classes = ('abraham_grampa_simpson',\n",
    "            'agnes_skinner',\n",
    "            'apu_nahasapeemapetilon',\n",
    "            'barney_gumble',\n",
    "            'bart_simpson',\n",
    "            'carl_carlson',\n",
    "            'charles_montgomery_burns',\n",
    "            'chief_wiggum',\n",
    "            'cletus_spuckler',\n",
    "            'comic_book_guy',\n",
    "            'disco_stu',\n",
    "            'edna_krabappel',\n",
    "            'fat_tony',\n",
    "            'gil',\n",
    "            'groundskeeper_willie',\n",
    "            'homer_simpson',\n",
    "            'kent_brockman',\n",
    "            'krusty_the_clown',\n",
    "            'lenny_leonard',\n",
    "            'lionel_hutz',\n",
    "            'lisa_simpson',\n",
    "            'maggie_simpson',\n",
    "            'marge_simpson',\n",
    "            'martin_prince',\n",
    "            'mayor_quimby',\n",
    "            'milhouse_van_houten',\n",
    "            'miss_hoover',\n",
    "            'moe_szyslak',\n",
    "            'ned_flanders',\n",
    "            'nelson_muntz',\n",
    "            'otto_mann',\n",
    "            'patty_bouvier',\n",
    "            'principal_skinner',\n",
    "            'professor_john_frink',\n",
    "            'rainier_wolfcastle',\n",
    "            'ralph_wiggum',\n",
    "            'selma_bouvier',\n",
    "            'sideshow_bob',\n",
    "            'sideshow_mel',\n",
    "            'snake_jailbird',\n",
    "            'troy_mcclure',\n",
    "            'waylon_smithers')\n",
    "class_encoder = {}\n",
    "for i in range(len(classes)):\n",
    "    class_encoder[classes[i]]=i\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = os.listdir(img_dir)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir,self.img_labels[idx])\n",
    "        image = PIL.Image.open(img_path)\n",
    "        label = self.img_labels[idx]\n",
    "        class_indicator = label.rfind('_')\n",
    "        class_str = label[:class_indicator]\n",
    "        label = class_encoder[class_str]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],std=[0.2023, 0.1994, 0.2010]),\n",
    "    transforms.Resize((32,32))\n",
    "])\n",
    "\n",
    "\n",
    "full_dataset = torchvision.datasets.ImageFolder(\"./characters\",transformations)\n",
    "train_dataset,valid_dataset = torch.utils.data.random_split(full_dataset,[0.7, 0.3])\n",
    "train_dataset, test_set = torch.utils.data.random_split(full_dataset,[0.8, 0.2])\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,num_workers=16)\n",
    "print(\"The number of images in a training set is: \", len(train_loader)*batch_size)\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "print(\"The number of images in a test set is: \", len(test_loader)*batch_size)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "print(\"The number of images in validation set is: \",len(valid_loader)*batch_size)\n",
    "print(\"The number of batches per epoch is: \", len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.ReLU()\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc1 = nn.Linear(512, 42)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.conv(input)\n",
    "        output = self.pool(output)\n",
    "        output = output.view(-1, 512)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "model = Network().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.1, patience=3, verbose=True, threshold=1e-2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import tqdm\n",
    "\n",
    "def saveModel():\n",
    "    path = \"./simpsons.pth\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def testAccuracy():\n",
    "    \n",
    "    model.eval()\n",
    "    metric = torchmetrics.F1Score(task=\"multiclass\", num_classes=42).to(device)\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            metric(predicted, labels)\n",
    "    f1 = metric.compute()\n",
    "\n",
    "    return f1\n",
    "\n",
    "def testAccuracy_1():\n",
    "\n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    metric = torchmetrics.F1Score(task=\"multiclass\", num_classes=42).to(device)\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "            metric(predicted, labels)\n",
    "    f1 = metric.compute()\n",
    "    print(\"F1 metric: \",f1)\n",
    "loss_metric =[]\n",
    "recall_metric=[]\n",
    "accuracy_metric=[]\n",
    "lr_metric=[]\n",
    "\n",
    "def train():\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    print(\"The model will be running on\", device, \"device\")\n",
    "    comment = f' batch_size = {batch_size} lr = {learning_rate}'\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "    for epoch in tqdm.tnrange(num_epochs,position=0,desc=\"Epochs\"):\n",
    "        losses = []\n",
    "        total_correct=0;\n",
    "        total_f1=0;\n",
    "        for _, (images, labels) in enumerate(tqdm.tqdm_notebook(train_loader,position=1,desc=\"Batch iter\",leave=True), 0):\n",
    "\n",
    "            images = Variable(images.to(device))\n",
    "            labels = Variable(labels.to(device))\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            total_correct+= get_num_correct(outputs, labels)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        mean_loss = sum(losses) / len(losses)\n",
    "        scheduler.step(mean_loss)\n",
    "        print(f\"Loss at epoch {epoch} = {mean_loss}\")\n",
    "        f1 = testAccuracy()\n",
    "        print(f\"For epoch {epoch} F1: {f1}\")\n",
    "        tb.add_scalar(\"Loss\", mean_loss, epoch)\n",
    "        tb.add_scalar(\"Correct\", total_correct, epoch)\n",
    "        tb.add_scalar(\"F1\", f1, epoch)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            saveModel()\n",
    "            best_f1 = f1\n",
    "\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "    tb.add_image(\"images\", grid)\n",
    "    tb.add_graph(model, images)\n",
    "    tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "def testClassess():\n",
    "    metric = torchmetrics.F1Score(task=\"multiclass\", num_classes=42,average=None).to(device)\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            metric(predicted, labels)\n",
    "    acc = metric.compute()\n",
    "    for i in range(number_of_labels):\n",
    "        print(f'F1 of {classes[i]} : {acc[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egors\\PycharmProjects\\simpsons_cnn\\venv\\lib\\site-packages\\torchinfo\\torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "C:\\Users\\egors\\PycharmProjects\\simpsons_cnn\\venv\\lib\\site-packages\\torch\\storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n"
     ]
    },
    {
     "data": {
      "text/plain": "=======================================================================================================================================================================================================================\nLayer (type (var_name))                  Input Shape               Output Shape              Param #                   Param %                   Kernel Shape              Mult-Adds                 Trainable\n=======================================================================================================================================================================================================================\nNetwork (Network)                        [128, 3, 32, 32]          [128, 42]                 --                             --                   --                        --                        True\n├─Sequential (conv)                      [128, 3, 32, 32]          [128, 512, 32, 32]        --                             --                   --                        --                        True\n│    └─Conv2d (0)                        [128, 3, 32, 32]          [128, 32, 32, 32]         896                         0.01%                   [3, 3]                    117,440,512               True\n│    └─BatchNorm2d (1)                   [128, 32, 32, 32]         [128, 32, 32, 32]         64                          0.00%                   --                        8,192                     True\n│    └─ReLU (2)                          [128, 32, 32, 32]         [128, 32, 32, 32]         --                             --                   --                        --                        --\n│    └─Conv2d (3)                        [128, 32, 32, 32]         [128, 64, 32, 32]         18,496                      0.26%                   [3, 3]                    2,424,307,712             True\n│    └─BatchNorm2d (4)                   [128, 64, 32, 32]         [128, 64, 32, 32]         128                         0.00%                   --                        16,384                    True\n│    └─ReLU (5)                          [128, 64, 32, 32]         [128, 64, 32, 32]         --                             --                   --                        --                        --\n│    └─Conv2d (6)                        [128, 64, 32, 32]         [128, 64, 32, 32]         36,928                      0.52%                   [3, 3]                    4,840,226,816             True\n│    └─BatchNorm2d (7)                   [128, 64, 32, 32]         [128, 64, 32, 32]         128                         0.00%                   --                        16,384                    True\n│    └─ReLU (8)                          [128, 64, 32, 32]         [128, 64, 32, 32]         --                             --                   --                        --                        --\n│    └─Conv2d (9)                        [128, 64, 32, 32]         [128, 128, 32, 32]        73,856                      1.04%                   [3, 3]                    9,680,453,632             True\n│    └─BatchNorm2d (10)                  [128, 128, 32, 32]        [128, 128, 32, 32]        256                         0.00%                   --                        32,768                    True\n│    └─ReLU (11)                         [128, 128, 32, 32]        [128, 128, 32, 32]        --                             --                   --                        --                        --\n│    └─Conv2d (12)                       [128, 128, 32, 32]        [128, 128, 32, 32]        147,584                     2.08%                   [3, 3]                    19,344,130,048            True\n│    └─BatchNorm2d (13)                  [128, 128, 32, 32]        [128, 128, 32, 32]        256                         0.00%                   --                        32,768                    True\n│    └─ReLU (14)                         [128, 128, 32, 32]        [128, 128, 32, 32]        --                             --                   --                        --                        --\n│    └─Conv2d (15)                       [128, 128, 32, 32]        [128, 256, 32, 32]        295,168                     4.16%                   [3, 3]                    38,688,260,096            True\n│    └─BatchNorm2d (16)                  [128, 256, 32, 32]        [128, 256, 32, 32]        512                         0.01%                   --                        65,536                    True\n│    └─ReLU (17)                         [128, 256, 32, 32]        [128, 256, 32, 32]        --                             --                   --                        --                        --\n│    └─Conv2d (18)                       [128, 256, 32, 32]        [128, 256, 32, 32]        590,080                     8.32%                   [3, 3]                    77,342,965,760            True\n│    └─BatchNorm2d (19)                  [128, 256, 32, 32]        [128, 256, 32, 32]        512                         0.01%                   --                        65,536                    True\n│    └─ReLU (20)                         [128, 256, 32, 32]        [128, 256, 32, 32]        --                             --                   --                        --                        --\n│    └─Conv2d (21)                       [128, 256, 32, 32]        [128, 512, 32, 32]        1,180,160                  16.65%                   [3, 3]                    154,685,931,520           True\n│    └─BatchNorm2d (22)                  [128, 512, 32, 32]        [128, 512, 32, 32]        1,024                       0.01%                   --                        131,072                   True\n│    └─ReLU (23)                         [128, 512, 32, 32]        [128, 512, 32, 32]        --                             --                   --                        --                        --\n│    └─Conv2d (24)                       [128, 512, 32, 32]        [128, 512, 32, 32]        2,359,808                  33.29%                   [3, 3]                    309,304,754,176           True\n│    └─BatchNorm2d (25)                  [128, 512, 32, 32]        [128, 512, 32, 32]        1,024                       0.01%                   --                        131,072                   True\n│    └─ReLU (26)                         [128, 512, 32, 32]        [128, 512, 32, 32]        --                             --                   --                        --                        --\n│    └─Conv2d (27)                       [128, 512, 32, 32]        [128, 512, 32, 32]        2,359,808                  33.29%                   [3, 3]                    309,304,754,176           True\n│    └─BatchNorm2d (28)                  [128, 512, 32, 32]        [128, 512, 32, 32]        1,024                       0.01%                   --                        131,072                   True\n│    └─ReLU (29)                         [128, 512, 32, 32]        [128, 512, 32, 32]        --                             --                   --                        --                        --\n├─AdaptiveAvgPool2d (pool)               [128, 512, 32, 32]        [128, 512, 1, 1]          --                             --                   --                        --                        --\n├─Linear (fc1)                           [128, 512]                [128, 42]                 21,546                      0.30%                   --                        2,757,888                 True\n=======================================================================================================================================================================================================================\nTotal params: 7,089,258\nTrainable params: 7,089,258\nNon-trainable params: 0\nTotal mult-adds (G): 925.74\n=======================================================================================================================================================================================================================\nInput size (MB): 1.57\nForward/backward pass size (MB): 5167.43\nParams size (MB): 28.36\nEstimated Total Size (MB): 5197.36\n======================================================================================================================================================================================================================="
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "\n",
    "\n",
    "torchinfo.summary(model, depth=2, input_size=(128, 3, 32,32), row_settings=[\"var_names\"], verbose=0, col_names=[\n",
    "\"input_size\", \"output_size\", \"num_params\", \"params_percent\", \"kernel_size\", \"mult_adds\", \"trainable\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be running on cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egors\\AppData\\Local\\Temp\\ipykernel_34944\\4222688759.py:53: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for epoch in tqdm.tnrange(num_epochs,position=0,desc=\"Epochs\"):\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0240f76f1d1d472ca15bcf4592201015"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egors\\AppData\\Local\\Temp\\ipykernel_34944\\4222688759.py:57: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for _, (images, labels) in enumerate(tqdm.tqdm_notebook(train_loader,position=1,desc=\"Batch iter\",leave=True), 0):\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "01d6e0a13b8b4217aff8793bc71b7b6c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0 = 3.130803936310397\n",
      "For epoch 0 F1: 0.23053033649921417\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84a8295c5eb4433fb6f8d413647de077"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1 = 2.5713713059898553\n",
      "For epoch 1 F1: 0.4147157073020935\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4789070f63114ec4aa9398f20619417d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 2 = 2.1095694403611978\n",
      "For epoch 2 F1: 0.49976110458374023\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a148e38461ff425da9b994694fd33955"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 3 = 1.6577868761907097\n",
      "For epoch 3 F1: 0.567367434501648\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0ce85aecfe5461389a2e368ecf2ec56"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 4 = 1.3786659122423361\n",
      "For epoch 4 F1: 0.6669852137565613\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "678b5840c90a4d129be622154cafc80a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 5 = 1.1735272871628972\n",
      "For epoch 5 F1: 0.7152412533760071\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6cf9f5d751344e158169cdf4316aa29e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 6 = 1.0344073522181911\n",
      "For epoch 6 F1: 0.6992355585098267\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26a05026ee044264a278adc1d68b4afd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 7 = 0.8993698981882051\n",
      "For epoch 7 F1: 0.785953164100647\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b57579f69b70401191cb7de425df2922"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 8 = 0.8210013768145146\n",
      "For epoch 8 F1: 0.7914476990699768\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batch iter:   0%|          | 0/131 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b9d7572c8eb4e1c94310632a08ca348"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 9 = 0.7244975398515017\n",
      "For epoch 9 F1: 0.8050644993782043\n",
      "Finished Training\n",
      "F1 of abraham_grampa_simpson : 0.5903307795524597\n",
      "F1 of agnes_skinner : 0.0\n",
      "F1 of apu_nahasapeemapetilon : 0.5116279125213623\n",
      "F1 of barney_gumble : 0.0\n",
      "F1 of bart_simpson : 0.5117772817611694\n",
      "F1 of carl_carlson : 0.0\n",
      "F1 of charles_montgomery_burns : 0.5548996329307556\n",
      "F1 of chief_wiggum : 0.5811403393745422\n",
      "F1 of cletus_spuckler : 0.0\n",
      "F1 of comic_book_guy : 0.3612903356552124\n",
      "F1 of disco_stu : 0.0\n",
      "F1 of edna_krabappel : 0.41999998688697815\n",
      "F1 of fat_tony : 0.0\n",
      "F1 of gil : 0.0\n",
      "F1 of groundskeeper_willie : 0.0\n",
      "F1 of homer_simpson : 0.5641025900840759\n",
      "F1 of kent_brockman : 0.20359280705451965\n",
      "F1 of krusty_the_clown : 0.7317073345184326\n",
      "F1 of lenny_leonard : 0.336448609828949\n",
      "F1 of lionel_hutz : 0.0\n",
      "F1 of lisa_simpson : 0.6090425252914429\n",
      "F1 of maggie_simpson : 0.0\n",
      "F1 of marge_simpson : 0.7880299091339111\n",
      "F1 of martin_prince : 0.0\n",
      "F1 of mayor_quimby : 0.0\n",
      "F1 of milhouse_van_houten : 0.5872340202331543\n",
      "F1 of miss_hoover : 0.0\n",
      "F1 of moe_szyslak : 0.5902702808380127\n",
      "F1 of ned_flanders : 0.650602400302887\n",
      "F1 of nelson_muntz : 0.20000000298023224\n",
      "F1 of otto_mann : 0.0\n",
      "F1 of patty_bouvier : 0.0\n",
      "F1 of principal_skinner : 0.6626865863800049\n",
      "F1 of professor_john_frink : 0.0\n",
      "F1 of rainier_wolfcastle : 0.0\n",
      "F1 of ralph_wiggum : 0.0\n",
      "F1 of selma_bouvier : 0.07407407462596893\n",
      "F1 of sideshow_bob : 0.7484143972396851\n",
      "F1 of sideshow_mel : 0.0\n",
      "F1 of snake_jailbird : 0.0\n",
      "F1 of troy_mcclure : 0.0\n",
      "F1 of waylon_smithers : 0.0\n",
      "F1 metric:  tensor(0.5862, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train()\n",
    "    print('Finished Training')\n",
    "    model = Network().to(device)\n",
    "    path = \"simpsons.pth\"\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    testClassess()\n",
    "    testAccuracy_1()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
